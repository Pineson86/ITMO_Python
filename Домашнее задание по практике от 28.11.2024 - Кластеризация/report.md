# Отчёт по кластеризации данных

## Описание задачи

Цель работы: применение различных алгоритмов кластеризации к игрушечному датасету и анализ их эффективности с помощью метрик. Также проведён сравнительный анализ результатов кластеризации.

## Использованный датасет

Датасет: **Wine Dataset** из библиотеки `sklearn`.  
Описание:
- Данные содержат химический состав 178 образцов вина из трёх классов.
- 13 числовых признаков, характеризующих химический состав вина.
- Целевая переменная (класс) используется только для оценки качества кластеризации.

## Предварительная обработка данных

1. **Стандартизация**: признаки стандартизированы с использованием `StandardScaler` для приведения их к одному масштабу.
2. **Отсутствие пропусков**: данные уже были чистыми, дополнительная обработка не требовалась.

## Использованные алгоритмы кластеризации

1. **KMeans** (К-средних)
2. **Agglomerative Clustering** (Агломеративная кластеризация)
3. **Spectral Clustering** (Спектральная кластеризация)
4. **Birch** (Балансировка итеративной кластеризации)
5. **MeanShift**
6. **DBSCAN**

## Метрики оценки

1. **Silhouette Score**: измеряет плотность кластеров. Чем ближе к 1, тем лучше.
2. **Adjusted Rand Index (ARI)**: сравнивает полученные кластеры с истинными метками. Чем ближе к 1, тем лучше.
3. **Homogeneity Score**: измеряет однородность кластеров. Ближе к 1 означает, что кластеры содержат только элементы одного класса.
4. **V-measure Score**: гармоническое среднее однородности и полноты кластеров.

## Результаты кластеризации

| Алгоритм            | Silhouette Score | Adjusted Rand Index | Homogeneity Score | V-measure Score |
|---------------------|------------------|---------------------|-------------------|-----------------|
| **KMeans**           | 0.2849           | 0.8975              | 0.8788            | 0.8759          |
| **Agglomerative**     | 0.2774           | 0.7899              | 0.7904            | 0.7865          |
| **Spectral**          | 0.2486           | 0.4446              | 0.4689            | 0.5725          |
| **Birch**             | 0.2774           | 0.7899              | 0.7904            | 0.7865          |
| **MeanShift**         | 0.2245           | -0.0064             | 0.0194            | 0.0353          |
| **DBSCAN**            | Невозможно вычислить (1 кластер) | -                 | -                | -               |

## Интерпретация результатов

1. **KMeans**: 
   - Показал лучшие результаты по большинству метрик.
   - Высокий ARI (0.8975) и Homogeneity Score (0.8788) говорят о хорошем совпадении кластеров с истинными метками классов.

2. **Agglomerative**:
   - Показатели чуть ниже, чем у KMeans.
   - Homogeneity Score (0.7904) и V-measure Score (0.7865) подтверждают качество кластеризации, хотя и с меньшей точностью.

3. **Spectral**:
   - Результаты хуже, особенно ARI (0.4446), что указывает на слабую связь с истинными метками классов.
   - Подходит для других задач, но не оптимален для данного датасета.

4. **Birch**:
   - Результаты аналогичны Agglomerative, что ожидаемо, так как алгоритмы имеют сходные принципы работы.

5. **MeanShift**:
   - Показал наихудшие результаты.
   - Низкие значения ARI (-0.0064) и V-measure (0.0353) указывают на слабую структуру кластеров.

6. **DBSCAN**:
   - Выделил только один кластер, из-за чего метрики не были рассчитаны.
   - Алгоритм плохо справляется с данными, не имеющими плотных локальных группировок.

## Выводы

- **Лучший алгоритм**: KMeans, так как он показал наилучшие метрики.
- **Проблемные алгоритмы**: MeanShift и DBSCAN, которые не подходят для данного набора данных.
- **Влияние числа кластеров**: Увеличение числа кластеров в KMeans и Agglomerative может ещё больше повысить точность кластеризации. Это требует дополнительного анализа.

